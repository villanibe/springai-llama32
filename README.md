# spring-ai-ollama 3.2

Example simple application showing how to use Spring AI and Open source LLM models.
Ollama is an inference server, to serve LLM models.

### Java development tooling

* Java 21
* Favourite Java IDE one of
    * [IntelliJ](https://www.jetbrains.com/idea/download)
    * [VSCode](https://code.visualstudio.com/)
    * [Eclipse Spring Tool Suite](https://spring.io/tools)

### Http Client

* A lightweight command line http client  [httpie](https://httpie.io/) or If you are handy with other tools such as Postman
feel free to use that as well.

### Containerization tools

* [Docker](https://docs.docker.com/engine/install/)

### Local AI Models

[ollama](https://ollama.com/)  makes running models on your laptop easy. 
You can run the models locally and learn how they work.

* Install ollama by following the instructions on the [ollama website](https://ollama.com/) .
